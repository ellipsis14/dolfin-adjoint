#!/usr/bin/env python

# Copyright (C) 2013 University of Oxford
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Lesser General Public License as published by
# the Free Software Foundation, version 3 of the License
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

"""
This is an ensemble of models for the Lorenz 1963 system, with a configuration
based on Eyink, Haine and Lea, Nonlinearity, 2004, pp. 1867 - 1889.
"""

from dolfin import *
from timestepping import *

import numpy
numpy.random.seed(0)

if "reorder_dofs_serial" in parameters:
  parameters["reorder_dofs_serial"] = False

solver = {"linear_solver":"bicgstab", "preconditioner":"bjacobi", "krylov_solver":{"relative_tolerance":1.0e-16, "absolute_tolerance":1.0e-16}}

Constant = StaticConstant

dt = Constant(0.01)
r = Constant(28.0)
sigma = Constant(10.0)
b = Constant(8.0 / 3.0)
T_spin = 10.0
T = 1.0
N_e = 100000
ns = int((T * (1.0 + 1.0e-6)) / float(dt))

mesh = UnitIntervalMesh(N_e)
base_space = FunctionSpace(mesh, "DG", 0)
space = MixedFunctionSpace([base_space for i in range(3)])
test, trial = TestFunction(space), TrialFunction(space)
test_1, test_2, test_3 = TestFunctions(space)

levels = TimeLevels(levels = [n, n + 1], cycle_map = {n:n + 1})
X = TimeFunction(levels, space, name = "X")

ic_x = StaticFunction(base_space)
ic_x.vector().set_local(20.0 * numpy.random.random(N_e) - 10.0);  ic_x.vector().apply("insert")
ic_y = StaticFunction(base_space)
ic_y.vector().set_local(20.0 * numpy.random.random(N_e) - 10.0);  ic_y.vector().apply("insert")
ic_z = StaticFunction(base_space)
ic_z.vector().set_local(20.0 * numpy.random.random(N_e) - 10.0);  ic_z.vector().apply("insert")

system = TimeSystem()
system.add_solve(inner(test, X[0]) * dx ==
  inner(test_1, ic_x) * dx +
  inner(test_2, ic_y) * dx +
  inner(test_3, ic_z) * dx, X[0], solver_parameters = solver)
x_n, y_n, z_n = split(X[n])
x_np1, y_np1, z_np1 = split(X[n + 1])
x_h = 0.5 * (x_n + x_np1)
y_h = 0.5 * (y_n + y_np1)
z_h = 0.5 * (z_n + z_np1)
system.add_solve((1.0 / dt) * inner(test, X[n + 1] - X[n]) * dx ==
  inner(test_1, sigma * (y_h - x_h)) * dx +
  inner(test_2, r * x_h - y_h - x_h * z_h) * dx +
  inner(test_3, -b * z_h + x_h * y_h) * dx, X[n + 1], solver_parameters = solver)

def update(s, cs = None):
  print "t = %.2f" % (max(s - 1, 0) * float(dt))
  return
system.set_update(update)

s_system = system.assemble(adjoint = False)
t = 0.0
while t * (1.0 + 1.0e-6) < T_spin:
  s_system.timestep()
  t += float(dt)
s_system.finalise()
del(s_system)

X_n = X[N].vector().array()
X_n.shape = (3, N_e)
ic_x.vector().set_local(X_n[0, :]);  ic_x.vector().apply("insert")
ic_y.vector().set_local(X_n[1, :]);  ic_y.vector().apply("insert")
ic_z.vector().set_local(X_n[2, :]);  ic_z.vector().apply("insert")
clear_caches(ic_x, ic_y, ic_z)

class Functional(TimeFunctional):
  def __init__(self):
    TimeFunctional.__init__(self)
    self.__der = derivative(split(X[n])[2] * dx, X[n])
    return
  def initialise(self, val = 0.0):
    self.__val = val
    return
  def value(self):
    return self.__val
  def addto(self, s):
    if s in [0, ns]:
      self.__val += 0.5 * assemble(split(X[n])[2] * dx)
    else:
      self.__val += assemble(split(X[n])[2] * dx)
    return
  def dependencies(self, s = None, non_symbolic = False):
    return [X[n]]
  def derivative(self, param, s):
    if s in [0, ns]:
      return 0.5 * self.__der
    else:
      return self.__der
  def set_min_s(self, min_s):
    self.__min_s = min_s
    return

system = system.assemble(adjoint = True, disk_period = 10, functional = Functional(), reassemble = True)

s = 0
t = 0.0
av = 0.5 * assemble(split(X[n])[2] * dx)
#soln = numpy.empty((ns * min(1000, N_e), 4))
while t * (1.0 + 1.0e-6) < T:
  system.timestep()
  t += float(dt)
  s += 1

#  X_n = X[n].vector().array()
#  X_n.shape = (3, N_e)
#  for i in range(min(1000, N_e)):
#    soln[(s - 1) * min(1000, N_e) + i, :] = [t, X_n[0, i], X_n[1, i], X_n[2, i]]
  if s == ns:
    av += 0.5 * assemble(split(X[n])[2] * dx)
  else:
    av += assemble(split(X[n])[2] * dx)

system.finalise()

system.verify_checkpoints()

J = system.compute_functional()
J_err = abs(J - av)

dJdr = system.compute_gradient(r)
dJdr_ref = 0.9600 * float(ns)  # Reference value from Eyink, Haine and Lea,
                               # Nonlinearity, 2004, pp. 1867 - 1889.
dJdr_err = abs(float(dJdr) - dJdr_ref)

orders = system.taylor_test(r, J = J, grad = dJdr, ntest = 2, fact = 1.0e-6)

print "J = %.17e (internal)" % (J / float(ns))
print "J = %.17e (external)" % (av / float(ns))
print "Error in J = %.17e" % (J_err / float(ns))
print "dJdr (computed)  = %.17e" % (float(dJdr) / float(ns))
print "dJdr (reference) = %.17e" % (dJdr_ref / float(ns))
print "Absolute error in dJdr = %.17e" % (dJdr_err / float(ns))
print "Relative error in dJdr = %.6f%%" % (100.0 * dJdr_err / dJdr_ref)

#from matplotlib.pylab import *
#subplot(131)
#scatter(soln[:, 1], soln[:, 2], color = "k", s = 1)
#subplot(132)
#scatter(soln[:, 1], soln[:, 3], color = "k", s = 1)
#subplot(133)
#scatter(soln[:, 2], soln[:, 3], color = "k", s = 1)
#show()

assert(J_err < 1.0e-16)
assert((orders > 1.99).all())
assert((dJdr_err / float(ns)) < 8.0e-2)